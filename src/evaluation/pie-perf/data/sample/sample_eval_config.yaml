model_generated_outputs_path: "src/evaluation/pie-perf/generated_outputs.jsonl"
inputs_outputs_basepath: "src/evaluation/pie-perf/codenet/public_test_cases/"
output_report_file_path: "evaluation_results/edit/runtime_efficiency/Meta-Llama-3-8B-Instruct/base_prompt/1_samples/generated_outputs.report"
language: "python"
num_problems_to_evaluate: -1
num_trials: 25
ignore_first_k: 0
max_time_per_run: 10
temp_dir: null
model_generated_potentially_faster_code_col: "generated_answers"
slow_code_col: "input"
reference_code_col: "target"
is_prompt_based: false
cpu_number: 0